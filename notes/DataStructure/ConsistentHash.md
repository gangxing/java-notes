一致性Hash

主要在分布式系统中用于负载均衡的路由计算，不管是路由请求，还是路由数据

当做为分片缓存，当某一个节点down掉时，对于一致性hash和传统hash两个方法来讲，两者丢失的数据是一样的，



两者的核心区别不在于是否有虚拟节点，而在于通过hash(key)和Node的映射逻辑。

引入虚拟节点的意义：

hash(key) -> [0,2^23],如果不引入虚拟节点，每个节点占据的环比例可能不一致，这就会导致每个节点承载的数据量差别很大，不满足均衡性

引入虚拟节点，如果虚拟节点足够多，那么少数的几个屋里节点就能很平均低占据整个环，也就是只要hashCode足够平均的话，就会很平均低落到这几个物理节点。

这个理由跟http://michaelnielsen.org/blog/consistent-hashing/

这篇文章里的说法吻合

至于当移除一个物理节点，其附属的虚拟节点也都会被移掉。

当作为集群数据存储（Cache）,一致性hash移动的数量更少 具体是少多少

先理论上来分析一下

Naive hash:

n-数据总条数

m-机器节点数量

当减少一台机器，需要移动的数据量

m/(m+1),通过程序试验，数据吻合，并且随着m越大，移动的比率越大。当m足够大的时候，接近100%。

至于公式的推导，搞不来

对于一致性hash

如果不引入虚拟节点，只需要将新增节点的前一个（顺时针）节点的数据量分一部分给新节点就行了

为了是每个节点承担的数据更均匀一点，引入虚拟节点之后，只需移动1/(m+1)/k,其中k是每个节点的replications



在作为分布式缓存来讲，如果用naive hash,当新增一个节点，原本存在的key因为取模改变之后而不能命中的

比率占 xxx

对一致性hash来讲

Miss 率是



对于一致性hash来讲，还有以下几个自然而然的问题：

1.怎么确定replicate的大小，考虑点：均衡性，动态增加节点后的数据移动

2.当增减一个节点后，怎么移动数据

3.当一次性增减多个节点，又该怎么移动数据？


